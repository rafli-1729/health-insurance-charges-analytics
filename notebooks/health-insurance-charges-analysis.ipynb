{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "82c1d090-95f4-427e-ad78-ee947d35b7d8",
    "_uuid": "e0c0b2fd-8eed-4e35-88e0-66bb4327d5d8",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# üìö 1. Standard Library and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "171584a0-dc43-412c-9021-c2b42ad1ab69",
    "_uuid": "ae24f1ee-332c-4d22-a61d-05acd454e990",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-19T13:37:54.978262Z",
     "iopub.status.busy": "2025-11-19T13:37:54.977966Z",
     "iopub.status.idle": "2025-11-19T13:38:24.689356Z",
     "shell.execute_reply": "2025-11-19T13:38:24.688258Z",
     "shell.execute_reply.started": "2025-11-19T13:37:54.978238Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library and Configuration Ready!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# --- 1. SYSTEM & ENVIRONMENT CONFIGURATION ---\n",
    "import os\n",
    "import random\n",
    "from warnings import filterwarnings\n",
    "\n",
    "# Matikan log TensorFlow yang tidak perlu (Set sebelum import TF)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# Abaikan warnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# --- Core Library ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.utils import (\n",
    "    set_seed, get_logger, clean_feature_names,\n",
    "    safe_assert_sufficient_rows\n",
    ")\n",
    "\n",
    "# --- Visualization ---\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from src.viz import (\n",
    "    plot_target, plot_correlation, plot_value_counts\n",
    ")\n",
    "\n",
    "\n",
    "# --- Scikit Learn ---\n",
    "# Model Selection & Evaluation\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    cross_validate,\n",
    "    cross_val_score,\n",
    "    train_test_split\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error\n",
    ")\n",
    "from src.evaluate import (\n",
    "    evaluate_final_model, plot_feature_importance_from_pipeline\n",
    ")\n",
    "\n",
    "# Preprocessing & Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    RobustScaler\n",
    ")\n",
    "from src.preprocess import (\n",
    "    build_preprocessor, fit_transform_df\n",
    ")\n",
    "\n",
    "\n",
    "# --- Deep Learning Frameworks ---\n",
    "# TensorFlow & Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Activation\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ReduceLROnPlateau\n",
    ")\n",
    "from src.dnn import (\n",
    "    build_dnn_model, run_dnn_cv,\n",
    "    train_final_dnn, explain_dnn_feature_importance\n",
    ")\n",
    "\n",
    "# ML Models\n",
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from src.tuning import tune_model\n",
    "\n",
    "# --- Global Constant ---\n",
    "N_SPLITS = 5\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 8\n",
    "DATA_PATH = 'data/insurance.csv'\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    try:\n",
    "        tf.config.experimental.enable_op_determinism()\n",
    "    except AttributeError:\n",
    "        print(\"Warning: tf.config.experimental.enable_op_determinism() tidak tersedia di versi TF ini.\")\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "print('Library and Configuration Ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6554c6e0-0a72-44d5-a5b9-68f5730f07d3",
    "_uuid": "3c79d15f-694b-42f5-b173-9f715a3dd17c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# üìä 2. Load Data\n",
    "\n",
    "## Dataset Penelitian: Medical Cost Personal Dataset\n",
    "\n",
    "Dataset yang digunakan dalam penelitian merupakan **Medical Cost Personal Dataset** yang diperoleh dari laman Kaggle (sumber: [Kaggle](https://www.kaggle.com/datasets/mirichoi0218/insurance/data)). Dataset ini berisi data individu yang diasuransikan, dengan tujuan untuk menganalisis faktor-faktor yang memengaruhi besarnya klaim medis (*medical charges*) yang ditanggung oleh perusahaan asuransi kesehatan.\n",
    "\n",
    "Secara keseluruhan, dataset ini terdiri atas **1.338 observasi** dan **7 variabel** yang mencakup karakteristik demografis, kondisi kesehatan, serta informasi biaya klaim. Adapun penjelasan tiap variabel adalah sebagai berikut.\n",
    "\n",
    "---\n",
    "\n",
    "### Deskripsi Variabel\n",
    "\n",
    "* **age**: Usia tertanggung utama (*primary beneficiary*) yang diasuransikan. Umur merupakan faktor risiko utama dalam klaim kesehatan karena berkorelasi positif dengan frekuensi dan keparahan klaim.\n",
    "* **sex**: Jenis kelamin tertanggung, terdiri atas kategori *female* dan *male*. Variabel ini digunakan untuk menilai adanya perbedaan biaya klaim antara laki-laki dan perempuan.\n",
    "* **bmi**: *Body Mass Index* (BMI), yaitu indeks massa tubuh yang dihitung dari rasio berat badan terhadap tinggi badan (kg/m¬≤). Nilai ideal berada pada kisaran 18,5‚Äì24,9. BMI digunakan sebagai indikator risiko kesehatan seperti obesitas yang berpotensi meningkatkan biaya klaim.\n",
    "* **children**: Jumlah anak atau tanggungan yang tercakup dalam polis asuransi kesehatan. Variabel ini menunjukkan beban keluarga dalam perlindungan asuransi.\n",
    "* **smoker**: Status kebiasaan merokok tertanggung (*yes* atau *no*). Faktor ini sangat berpengaruh terhadap besarnya premi maupun klaim karena berkaitan langsung dengan risiko penyakit kronis.\n",
    "* **region**: Wilayah tempat tinggal tertanggung di Amerika Serikat, dengan kategori *northeast*, *southeast*, *southwest*, dan *northwest*. Variabel ini dapat mencerminkan perbedaan biaya layanan kesehatan antar wilayah.\n",
    "* **charges**: Total biaya medis individual yang ditagihkan kepada perusahaan asuransi (*individual medical costs billed by health insurance*). Variabel ini menjadi variabel target (*dependent variable*) yang akan diprediksi dalam penelitian ini.\n",
    "\n",
    "---\n",
    "\n",
    "Dengan karakteristik tersebut, dataset ini dinilai sesuai untuk mendukung analisis faktor-faktor yang memengaruhi besarnya klaim asuransi kesehatan menggunakan pendekatan *machine learning*. Selain itu, variabel-variabelnya memungkinkan untuk dilakukan interpretasi dari sudut pandang aktuaria, terutama dalam konteks *risk classification* dan *expected claim cost estimation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "049e005f-07b9-4dd8-b223-e0236281f8e5",
    "_uuid": "5f4d1213-1a3e-457b-8710-893f09e0b115",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-19T13:38:24.746458Z",
     "iopub.status.busy": "2025-11-19T13:38:24.746162Z",
     "iopub.status.idle": "2025-11-19T13:38:24.857527Z",
     "shell.execute_reply": "2025-11-19T13:38:24.856517Z",
     "shell.execute_reply.started": "2025-11-19T13:38:24.746432Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/insurance.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m insurance = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/insurance.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m insurance.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/insurance.csv'"
     ]
    }
   ],
   "source": [
    "insurance = pd.read_csv('data/insurance.csv')\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\n",
      "\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "84ce4e19-1ceb-48d9-b093-8f666184d2cb",
    "_uuid": "d5ed1673-e790-4e7d-a33f-8c84fc52e2b2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-19T13:38:24.860019Z",
     "iopub.status.busy": "2025-11-19T13:38:24.85971Z",
     "iopub.status.idle": "2025-11-19T13:38:24.897918Z",
     "shell.execute_reply": "2025-11-19T13:38:24.896854Z",
     "shell.execute_reply.started": "2025-11-19T13:38:24.859992Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('Statistic descriptive of numerical features\\n')\n",
    "print(insurance.describe())\n",
    "\n",
    "print('\\nStatistic descriptive of categorical features\\n')\n",
    "print(insurance.describe(include='object'))\n",
    "\n",
    "print('\\nNumber of missing value each feature\\n')\n",
    "print(insurance.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "181ac439-f0ae-4183-97e1-a511f70a26ea",
    "_uuid": "1442982e-ba76-4722-a2f3-3b6ac7a5d2ff",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-19T13:38:24.899391Z",
     "iopub.status.busy": "2025-11-19T13:38:24.899095Z",
     "iopub.status.idle": "2025-11-19T13:38:24.916713Z",
     "shell.execute_reply": "2025-11-19T13:38:24.915407Z",
     "shell.execute_reply.started": "2025-11-19T13:38:24.899367Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check duplicates ‚Üí drop ‚Üí verify\n",
    "print(\"Missing value before:\", insurance.duplicated().sum())\n",
    "\n",
    "insurance.drop_duplicates(inplace=True)\n",
    "print(\"Missing value after :\", insurance.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "35f02e3e-41b2-4734-bfe7-3e6f9ee0b3c9",
    "_uuid": "eff3017b-13df-4081-b196-194f3bdb3c72",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# üîé 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "38da67f7-22df-465a-aea1-0cb6899330ef",
    "_uuid": "98964fc4-a204-472f-ad2e-8416c523daef",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-19T13:38:24.918028Z",
     "iopub.status.busy": "2025-11-19T13:38:24.917705Z",
     "iopub.status.idle": "2025-11-19T13:38:24.926391Z",
     "shell.execute_reply": "2025-11-19T13:38:24.925361Z",
     "shell.execute_reply.started": "2025-11-19T13:38:24.917997Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Devide datasets into two part, predictor and target\n",
    "\n",
    "X = insurance.drop(columns=['charges'])\n",
    "y = insurance.charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0a44f9ee-4071-4fb0-b2d8-ff8f822712cc",
    "_uuid": "f0373c9f-2427-4d76-aa22-7bb75af77910",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-19T13:38:24.927633Z",
     "iopub.status.busy": "2025-11-19T13:38:24.927366Z",
     "iopub.status.idle": "2025-11-19T13:38:25.757906Z",
     "shell.execute_reply": "2025-11-19T13:38:25.756918Z",
     "shell.execute_reply.started": "2025-11-19T13:38:24.92761Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_target(y, log=False)\n",
    "plot_target(y, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0fdc134c-3077-4291-a9d2-e279edbceefa",
    "_uuid": "3f3ee143-004b-4f6f-b863-744a69db3364",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Distribusi charges menunjukkan pola yang sangat right-skewed, di mana sebagian besar individu membayar biaya asuransi dalam rentang rendah hingga menengah (sekitar di bawah 15.000), sementara hanya sebagian kecil yang memiliki biaya sangat tinggi hingga lebih dari 60.000. Ekor panjang di sisi kanan menandakan adanya outliers atau kelompok kecil dengan biaya medis ekstrem, yang kemungkinan besar dipengaruhi oleh faktor seperti status perokok atau kondisi kesehatan tertentu. Pola ini juga menunjukkan bahwa variabel target tidak berdistribusi normal, sehingga transformasi seperti log-transform dapat membantu model regresi untuk mempelajari pola dengan lebih stabil dan mengurangi efek ekstrem dari nilai-nilai tinggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c72ead9c-8ea7-4a5c-a384-61ea0ed15712",
    "_uuid": "1b9e5f6c-903a-41b7-8eb6-c54dad507531",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-19T13:38:25.759325Z",
     "iopub.status.busy": "2025-11-19T13:38:25.758967Z",
     "iopub.status.idle": "2025-11-19T13:38:27.321888Z",
     "shell.execute_reply": "2025-11-19T13:38:27.320658Z",
     "shell.execute_reply.started": "2025-11-19T13:38:25.759293Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "numerical_features=X.select_dtypes(include=np.number).columns\n",
    "categorical_features=X.select_dtypes(include='object').columns\n",
    "\n",
    "plot_features(X, numerical_features, categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eb5a6a1b-d7f9-470a-b0a9-fc8f922666a3",
    "_uuid": "e8485e97-0edc-4dde-9b45-8909f1848964",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Distribusi umur (age) tampak cukup merata dari usia 20 hingga 60 tahun tanpa pola khusus, menunjukkan tidak ada dominasi kelompok umur tertentu. Fitur BMI memiliki pola mendekati distribusi normal dengan pusat di sekitar 30, menunjukkan mayoritas peserta memiliki BMI overweight. Jumlah anak (children) didominasi oleh nilai 0‚Äì1, menandakan sebagian besar individu tidak memiliki anak atau hanya satu. Komposisi jenis kelamin (sex) relatif seimbang antara laki-laki dan perempuan. Status perokok (smoker) sangat tidak seimbang, dengan mayoritas besar adalah non-smoker. Distribusi wilayah (region) merata di empat region tanpa ada dominasi signifikan, sehingga tidak ada sampling bias besar dari wilayah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a9d77384-5ac9-41c7-978e-4f98298f889d",
    "_uuid": "4e15b874-4e95-4277-bbca-c7be446fef26",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-19T13:38:27.323254Z",
     "iopub.status.busy": "2025-11-19T13:38:27.322956Z",
     "iopub.status.idle": "2025-11-19T13:38:27.608871Z",
     "shell.execute_reply": "2025-11-19T13:38:27.607848Z",
     "shell.execute_reply.started": "2025-11-19T13:38:27.323225Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_numerical_correlation(X, numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2d000d1a-259b-4535-95a1-d3e499ad42d6",
    "_uuid": "7fc77284-5e15-411b-a6e9-d5ba0c5b3e59",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Heatmap menunjukkan bahwa hubungan antar fitur numerik (age, bmi, children) sangat lemah, dengan koefisien korelasi yang semuanya mendekati nol. Age hanya memiliki korelasi kecil dengan BMI, dan jumlah anak hampir tidak berhubungan dengan dua fitur lainnya. Ini mengindikasikan bahwa ketiga fitur tersebut cenderung berdiri sendiri dan tidak memiliki hubungan linear yang kuat satu sama lain, sehingga masing-masing kemungkinan berkontribusi secara independen terhadap variabel target (biaya insurance) dan tidak menimbulkan masalah multikolinearitas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "04a94176-e156-4771-ab3c-2c0d6210282a",
    "_uuid": "39dfd269-ef46-419c-a283-49d01e85ef7b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# üìà 4. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f6eab8b0-6286-4fab-8438-47f3c296cebd",
    "_uuid": "87d98e3c-8771-4628-87cc-14bc8fbeb218",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-19T13:38:27.611942Z",
     "iopub.status.busy": "2025-11-19T13:38:27.611632Z",
     "iopub.status.idle": "2025-11-19T13:38:27.618676Z",
     "shell.execute_reply": "2025-11-19T13:38:27.617741Z",
     "shell.execute_reply.started": "2025-11-19T13:38:27.611919Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "high_cardinality_cols = [features for features in categorical_features if X[features].nunique()>10]\n",
    "print('High cardinality column: ', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ac1486c4-8bd4-43a3-8896-33b3b2c9dada",
    "_uuid": "e8bbb6ba-3bd2-4e05-8071-9aef5bf18026",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Semua variabel kategorikal tidak ada yang memiliki cardinality yang tinggi, semua variabel kategorik akan dilakukan One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0c46d3f5-63ea-4d93-8526-22412fb96dce",
    "_uuid": "d40c2c18-96f9-4411-8d4e-6bbebda3375e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Untuk membantu model menangkap pola risiko yang kompleks dan non-linier, kita membuat variabel-variabel turunan berikut:\n",
    "\n",
    "* **`bmi_encoded` (Kategori BMI)**\n",
    "    * **Tujuan:** Mengubah variabel numerik kontinu (`bmi`) menjadi variabel kategori ordinal (0, 1, 2, 3).\n",
    "    * **Penjelasan:** Hubungan BMI dengan biaya kesehatan seringkali bertingkat (*step-function*), bukan garis lurus. Pengelompokan ini membantu model membedakan risiko antara kategori berat badan (misal: *Underweight, Normal, Overweight, Obese*) secara lebih tegas.\n",
    "    * *Dibuat dari: `bmi`*\n",
    "\n",
    "* **`smoker_obese_interaction` (Interaksi Perokok & Obesitas)**\n",
    "    * **Tujuan:** Membuat fitur biner yang bernilai `1` jika seseorang adalah perokok **DAN** memiliki BMI tinggi (*Overweight/Obese* - kategori 2 atau 3).\n",
    "    * **Penjelasan:** Ini adalah \"Double Whammy Effect\". Dalam aktuaria, risiko kesehatan perokok yang juga obesitas seringkali **multiplikatif**, bukan aditif. Biaya mereka biasanya jauh lebih tinggi dibandingkan yang hanya perokok atau hanya obesitas.\n",
    "    * *Dibuat dari: `smoker` dan `bmi_encoded`*\n",
    "\n",
    "* **`has_dependent_or_high_risk` (Tanggungan atau Risiko Gaya Hidup)**\n",
    "    * **Tujuan:** Membuat fitur biner yang menandai jika seseorang punya anak **ATAU** merupakan perokok.\n",
    "    * **Penjelasan:** Menggabungkan dua faktor pemicu biaya berbeda: beban finansial keluarga (anak) atau beban risiko kesehatan (rokok). Ini mengelompokkan profil \"High Liability\" secara umum.\n",
    "    * *Dibuat dari: `children` dan `smoker`*\n",
    "\n",
    "* **`smoker_age_interaction` (Interaksi Usia Khusus Perokok)**\n",
    "    * **Tujuan:** Menyimpan nilai umur asli hanya jika orang tersebut perokok (jika tidak, nilainya 0).\n",
    "    * **Penjelasan:** Dampak penuaan pada tubuh perokok mungkin lebih merusak (akselerasi biaya) dibandingkan non-perokok. Fitur ini mengizinkan model memberikan \"bobot\" atau koefisien yang berbeda untuk umur pada kelompok perokok.\n",
    "    * *Dibuat dari: `smoker` dan `age`*\n",
    "\n",
    "* **`smoker_obese_aged_interaction` (Risiko Ekstrem: Tua, Merokok, Gemuk)**\n",
    "    * **Tujuan:** Fitur biner untuk segmen risiko sangat tinggi: Perokok + BMI Tinggi + Usia di atas 45 tahun.\n",
    "    * **Penjelasan:** Ini mengisolasi kelompok \"*Very High Risk*\". Seringkali model gagal memprediksi nilai ekstrem (*outlier*) yang sangat mahal. Fitur ini memberi sinyal khusus pada model bahwa kelompok ini kemungkinan besar memiliki klaim raksasa.\n",
    "    * *Dibuat dari: `smoker`, `bmi_encoded`, dan `age`*\n",
    "\n",
    "* **`bmi_smoker_continuous` (Interaksi BMI Kontinu Khusus Perokok)**\n",
    "    * **Tujuan:** Menyimpan nilai BMI asli hanya jika orang tersebut perokok.\n",
    "    * **Penjelasan:** Serupa dengan interaksi usia, kenaikan 1 poin BMI pada perokok mungkin berdampak lebih besar terhadap biaya daripada kenaikan 1 poin BMI pada non-perokok (efek sinergis pada jantung/paru).\n",
    "    * *Dibuat dari: `smoker` dan `bmi`*\n",
    "\n",
    "* **`age_sq` (Usia Kuadrat)**\n",
    "    * **Tujuan:** *Polynomial feature* untuk menangkap hubungan kuadratik pada usia.\n",
    "    * **Penjelasan:** Biaya kesehatan biasanya tidak naik secara linier seiring bertambahnya usia, melainkan melengkung ke atas (eksponensial/kuadratik) terutama di usia tua.\n",
    "    * *Dibuat dari: `age`*\n",
    "\n",
    "* **`bmi_sq` (BMI Kuadrat)**\n",
    "    * **Tujuan:** *Polynomial feature* untuk menangkap hubungan kuadratik pada BMI.\n",
    "    * **Penjelasan:** Risiko kesehatan mungkin naik drastis (kurva berbentuk J atau U) pada angka BMI yang sangat ekstrem.\n",
    "    * *Dibuat dari: `bmi`*\n",
    "\n",
    "* **`age_bmi_interaction` (Interaksi Usia dan BMI)**\n",
    "    * **Tujuan:** Perkalian antara usia dan BMI.\n",
    "    * **Penjelasan:** Dampak obesitas mungkin menjadi lebih parah seiring bertambahnya usia. Menjadi gemuk di usia 50 tahun mungkin membawa risiko komplikasi (dan biaya) yang lebih besar daripada gemuk di usia 20 tahun.\n",
    "    * *Dibuat dari: `age` dan `bmi`*\n",
    "\n",
    "* **`sex_smoker_interaction` (Interaksi Gender & Rokok)**\n",
    "    * **Tujuan:** Fitur biner khusus untuk Laki-laki yang Merokok.\n",
    "    * **Penjelasan:** Menguji hipotesis apakah ada perbedaan pola klaim antara perokok pria dan wanita (misalnya karena perbedaan intensitas merokok atau kerentanan biologis).\n",
    "    * *Dibuat dari: `sex` dan `smoker`*\n",
    "\n",
    "* **`non_smoker_high_risk` (Risiko Tinggi Non-Perokok)**\n",
    "    * **Tujuan:** Mengidentifikasi orang yang **bukan** perokok, tapi Tua (>45) dan Berat Badan Berlebih.\n",
    "    * **Penjelasan:** Menangkap segmen risiko murni dari faktor metabolik dan penuaan tanpa pengaruh rokok. Ini membantu model membedakan sumber risiko biaya.\n",
    "    * *Dibuat dari: `smoker`, `bmi_encoded`, dan `age`*\n",
    "\n",
    "* **`log_charges` (Transformasi Log pada Target)**\n",
    "    * **Tujuan:** Membuat variabel target baru dengan menerapkan transformasi logaritma natural (`np.log`) pada variabel `charges` asli.\n",
    "    * **Penjelasan:** Distribusi data `charges` asli sangat miring ke kanan (*right-skewed*). Distribusi yang miring ini melanggar asumsi banyak model dan dapat menurunkan akurasi. `log_charges` membuat distribusi target lebih normal (simetris).\n",
    "    * *Dibuat dari: `charges`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f9ba1ef7-b126-4a56-8ddd-4de1b1f32ba9",
    "_uuid": "9df74762-1457-43e7-9e42-c6571552f25a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-19T13:38:27.620241Z",
     "iopub.status.busy": "2025-11-19T13:38:27.619906Z",
     "iopub.status.idle": "2025-11-19T13:38:27.650866Z",
     "shell.execute_reply": "2025-11-19T13:38:27.649506Z",
     "shell.execute_reply.started": "2025-11-19T13:38:27.620213Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bins = [-np.inf, 18.5, 25, 30, np.inf]\n",
    "labels = [0, 1, 2, 3]\n",
    "\n",
    "insurance['bmi_encoded'] = pd.cut(insurance['bmi'], bins=bins, labels=labels)\n",
    "\n",
    "insurance['smoker_obese_interaction'] = np.where(\n",
    "    (insurance['smoker'] == 'yes') & (insurance['bmi_encoded'].isin([2, 3])),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "insurance['has_dependent_or_high_risk'] = np.where(\n",
    "    (insurance['children'] > 0) | (insurance['smoker'] == 'yes'),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "\n",
    "insurance['smoker_age_interaction'] = np.where(\n",
    "    insurance['smoker'] == 'yes',\n",
    "    insurance['age'],\n",
    "    0\n",
    ")\n",
    "\n",
    "insurance['smoker_obese_aged_interaction'] = np.where(\n",
    "    (insurance['smoker'] == 'yes') &\n",
    "    (insurance['bmi_encoded'].isin([2, 3])) &\n",
    "    (insurance['age'] > 45),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "insurance['bmi_smoker_continuous'] = np.where(\n",
    "    insurance['smoker'] == 'yes',\n",
    "    insurance['bmi'],\n",
    "    0\n",
    ")\n",
    "insurance['age_sq'] = insurance['age'] ** 2\n",
    "\n",
    "insurance['bmi_sq'] = insurance['bmi'] ** 2\n",
    "insurance['age_bmi_interaction'] = insurance['age'] * insurance['bmi']\n",
    "insurance['sex_smoker_interaction'] = np.where(\n",
    "    (insurance['smoker'] == 'yes') & (insurance['sex'] == 'male'),\n",
    "    1, 0\n",
    ")\n",
    "insurance['non_smoker_high_risk'] = np.where(\n",
    "    (insurance['smoker'] == 'no') &\n",
    "    (insurance['bmi_encoded'].isin([2, 3])) &\n",
    "    (insurance['age'] > 45),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "insurance['log_charges'] = np.log(insurance['charges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:38:27.652261Z",
     "iopub.status.busy": "2025-11-19T13:38:27.652009Z",
     "iopub.status.idle": "2025-11-19T13:38:27.684417Z",
     "shell.execute_reply": "2025-11-19T13:38:27.683454Z",
     "shell.execute_reply.started": "2025-11-19T13:38:27.65224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "insurance.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9914dacc-4bf9-4c34-8cd5-b016140a0c03",
    "_uuid": "08743edb-c9e6-48c1-923d-7054789f5f8a",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Data Setup & Preprocessing Initialization\n",
    "\n",
    "Tahap ini bertujuan untuk mempersiapkan data latih dan menginisialisasi komponen *preprocessing* menggunakan fungsi utilitas modular yang telah kita buat sebelumnya.\n",
    "\n",
    "### 1. Feature Selection & Target Definition\n",
    "\n",
    "Kita memisahkan kolom menjadi fitur (X) dan target (y) secara otomatis agar prosesnya dinamis:\n",
    "\n",
    "* **`DROP_COLS`**: Mendefinisikan kolom target (`charges`) dan variannya (`log_charges`) untuk dikecualikan dari daftar fitur agar tidak terjadi kebocoran data (*data leakage*).\n",
    "* **`NUM_FEATS` & `CAT_FEATS`**: Menggunakan `select_dtypes` untuk memisahkan nama kolom numerik dan kategorikal secara otomatis, dikurangi kolom yang ada di `DROP_COLS`.\n",
    "* **`X` & `y`**:\n",
    "    * `X`: Menggabungkan daftar fitur numerik dan kategorikal sebagai input model.\n",
    "    * `y`: Menggunakan `charges` (nilai asli) sebagai target prediksi.\n",
    "\n",
    "### 2. Preprocessor Initialization\n",
    "\n",
    "* **`my_preprocessor`**: Kita memanggil fungsi utilitas **`get_preprocessor(NUM_FEATS, CAT_FEATS)`** yang telah kita definisikan di bagian *Utility Functions*.\n",
    "* Fungsi ini secara otomatis membungkus logika transformasi standar:\n",
    "    * **Numerik**: Diterapkan **`StandardScaler`** untuk menstandarisasi skala data.\n",
    "    * **Kategorikal**: Diterapkan **`OneHotEncoder`** untuk mengubah data teks menjadi format numerik biner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:38:27.686067Z",
     "iopub.status.busy": "2025-11-19T13:38:27.685832Z",
     "iopub.status.idle": "2025-11-19T13:38:27.704401Z",
     "shell.execute_reply": "2025-11-19T13:38:27.703425Z",
     "shell.execute_reply.started": "2025-11-19T13:38:27.686048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Setup Data\n",
    "DROP_COLS = ['log_charges', 'charges']\n",
    "NUM_FEATS = insurance.select_dtypes(include=np.number).columns.difference(DROP_COLS)\n",
    "CAT_FEATS = insurance.select_dtypes(include='object').columns.difference(DROP_COLS)\n",
    "\n",
    "X = insurance[list(NUM_FEATS) + list(CAT_FEATS)]\n",
    "y = insurance['charges']\n",
    "\n",
    "# preprocessor\n",
    "my_preprocessor = get_preprocessor(NUM_FEATS, CAT_FEATS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Optimization Phase\n",
    "\n",
    "Pada tahap ini, kita menjalankan proses pelatihan model secara sistematis menggunakan *workflow* modular yang telah kita bangun. Kita akan membandingkan dua algoritma *Gradient Boosting* terpopuler: **XGBoost** dan **LightGBM**.\n",
    "\n",
    "Setiap model akan melalui dua fase utama: **Tuning** dan **Evaluation**.\n",
    "\n",
    "### 1. Phase A: Hyperparameter Tuning (`tune_model`)\n",
    "Kita menggunakan fungsi utilitas `tune_model` yang memanfaatkan **Optuna** untuk mencari kombinasi parameter terbaik secara otomatis.\n",
    "\n",
    "* **Strategi Pencarian:** Fungsi ini memanggil `get_xgb_search_space` atau `get_lgbm_search_space` untuk menentukan rentang parameter yang akan diuji (misalnya: `learning_rate`, `max_depth`, `num_leaves`).\n",
    "* **Metode Validasi:** Menggunakan **3-Fold Cross-Validation** (seperti yang didefinisikan di dalam fungsi `tune_model`) untuk mempercepat proses pencarian tanpa mengorbankan validitas data.\n",
    "* **Optimasi:** Optuna akan menjalankan **100 trials**, mencoba meminimalkan skor *Mean Absolute Error* (MAE).\n",
    "\n",
    "### 2. Phase B: Robust Evaluation (`evaluate_final_model`)\n",
    "Setelah parameter terbaik (`best_params`) ditemukan, kita tidak langsung mempercayai hasil tuning tersebut begitu saja. Kita memvalidasinya ulang menggunakan fungsi `evaluate_final_model`.\n",
    "\n",
    "* **Pipeline Final:** Parameter terbaik disuntikkan ke dalam model baru dan dibungkus kembali dengan *preprocessor*.\n",
    "* **Evaluasi Ketat:** Kita meningkatkan validasi menjadi **5-Fold Cross-Validation**. Ini memberikan estimasi performa yang lebih stabil dan tidak bias dibandingkan saat fase tuning.\n",
    "* **Metrik Lengkap:** Fungsi ini akan mencetak skor rata-rata untuk **R2** (daya jelaskan model), **MAE** (kesalahan absolut), dan **RMSE** (kesalahan kuadratik) untuk memastikan model benar-benar robust sebelum digunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:38:27.705618Z",
     "iopub.status.busy": "2025-11-19T13:38:27.705297Z",
     "iopub.status.idle": "2025-11-19T13:40:31.27517Z",
     "shell.execute_reply": "2025-11-19T13:40:31.274461Z",
     "shell.execute_reply.started": "2025-11-19T13:38:27.705585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# === 1. XGBoost Workflow ===\n",
    "# Step A: Tune\n",
    "xgb_best_params = tune_model(\n",
    "    model_cls=XGBRegressor,\n",
    "    search_space_func=get_xgb_search_space,\n",
    "    X=X, y=y, preprocessor=my_preprocessor,\n",
    "    n_trials=100, study_name=\"XGBoost\"\n",
    ")\n",
    "\n",
    "# Step B: Evaluate\n",
    "xgb_pipeline = evaluate_final_model(XGBRegressor, xgb_best_params, X, y, my_preprocessor)\n",
    "\n",
    "\n",
    "# === 2. LightGBM Workflow ===\n",
    "# Step A: Tune\n",
    "lgbm_best_params = tune_model(\n",
    "    model_cls=LGBMRegressor,\n",
    "    search_space_func=get_lgbm_search_space,\n",
    "    X=X, y=y, preprocessor=my_preprocessor,\n",
    "    n_trials=100, study_name=\"LightGBM\"\n",
    ")\n",
    "\n",
    "# Step B: Evaluate\n",
    "lgbm_pipeline = evaluate_final_model(LGBMRegressor, lgbm_best_params, X, y, my_preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "39216f6a-d75d-437a-850f-71f4df66b072",
    "_uuid": "c75b9733-260b-48f4-ad4b-2f4229b9564c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Model Evaluation & Interpretation\n",
    "\n",
    "Berdasarkan hasil *Hyperparameter Tuning* dan *5-Fold Cross-Validation*, berikut adalah analisis performa model prediksi biaya kesehatan (*charges*):\n",
    "\n",
    "### 1. Perbandingan Model (XGBoost vs LightGBM)\n",
    "\n",
    "| Metric | XGBoost (Winner) üèÜ | LightGBM | Selisih |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **R2 Score** | **0.8584** | 0.8516 | XGBoost +0.68% |\n",
    "| **MAE** | **`$2,454.01`** | `$2,563.73` | XGBoost lebih akurat ~`$110` |\n",
    "| **RMSE** | **`$4,500.18`** | `$4,608.39` | XGBoost lebih stabil terhadap *outlier* |\n",
    "\n",
    "**Kesimpulan Teknis:**\n",
    "**XGBoost** terbukti lebih superior dibandingkan LightGBM di semua metrik pengujian. Model ini mampu menjelaskan **85.84%** variabilitas dari biaya klaim kesehatan, yang merupakan angka yang sangat solid untuk data asuransi yang memiliki varians alami yang tinggi.\n",
    "\n",
    "### 2. Interpretasi Metrik dalam Konteks Asuransi\n",
    "\n",
    "#### a. R2 Score (0.8584) - \"Explanatory Power\"\n",
    "Model kita berhasil menangkap pola utama risiko. Artinya, fitur-fitur yang kita rekayasa (seperti `smoker_obese_interaction`, `bmi_encoded`, dll) sangat efektif. Sisa ~14% variabilitas yang tidak tertangkap kemungkinan adalah faktor acak (kecelakaan, penyakit mendadak tak terduga) atau variabel yang tidak tersedia di dataset (riwayat medis keluarga, genetik).\n",
    "\n",
    "#### b. MAE (Mean Absolute Error): ~`$2,454`\n",
    "* **Artinya:** Secara rata-rata, prediksi premi/klaim kita meleset (kurang atau lebih) sebesar **2,454 USD** dari tagihan aslinya.\n",
    "* **Implikasi Bisnis:** Dalam penetapan harga (*pricing*), ini adalah rata-rata \"ketidakpastian\" per polis. Jika margin keuntungan asuransi per orang lebih kecil dari angka ini, perusahaan berisiko rugi pada level individu, namun bisa tertutupi oleh hukum bilangan besar (*law of large numbers*) jika agregatnya akurat.\n",
    "\n",
    "#### c. Gap antara MAE (`$2,454`) dan RMSE (`$4,500`)\n",
    "* RMSE jauh lebih tinggi daripada MAE (hampir 2x lipat).\n",
    "* **Artinya:** Data klaim asuransi memiliki **Outlier Ekstrem** (Klaim Katastropik). Model terkadang melakukan kesalahan prediksi yang *sangat besar* pada kasus-kasus mahal (misalnya: memprediksi **`$10k`** padahal klaim aslinya **`$50k`**).\n",
    "* **Risiko:** Model mungkin sedikit *underfitting* pada kasus penyakit berat yang biayanya meledak, yang mana wajar karena kasus tersebut jarang terjadi (*sparse data*).\n",
    "\n",
    "### 3. Stabilitas Model (Cross-Validation Analysis)\n",
    "Melihat hasil per-*fold* pada XGBoost:\n",
    "* **Best Case (Fold 1):** R2 0.90 (Sangat Akurat)\n",
    "* **Worst Case (Fold 2):** R2 0.82 (Cukup Akurat)\n",
    "* **Analisis:** Variasi antara 0.82 hingga 0.90 menunjukkan bahwa model cukup stabil, namun ada sebagian kecil data (Fold 2) yang \"sulit\" diprediksi. Ini mungkin berisi kelompok pasien dengan profil aneh (misal: muda, tidak merokok, tapi klaimnya tinggi karena penyakit bawaan).\n",
    "\n",
    "### ‚úÖ Rekomendasi Akhir\n",
    "Kita akan menggunakan **XGBoost** sebagai model final (*champion model*). Performanya secara konsisten lebih baik dalam meminimalkan risiko kesalahan harga (*pricing error*) dibandingkan LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:40:31.277083Z",
     "iopub.status.busy": "2025-11-19T13:40:31.276394Z",
     "iopub.status.idle": "2025-11-19T13:40:32.951049Z",
     "shell.execute_reply": "2025-11-19T13:40:32.950082Z",
     "shell.execute_reply.started": "2025-11-19T13:40:31.277058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualisasi XGBoost\n",
    "df_imp_xgb = plot_feature_importance(xgb_pipeline, X, y, model_name=\"XGBoost\")\n",
    "\n",
    "# Visualisasi LightGBM\n",
    "df_imp_lgbm = plot_feature_importance(lgbm_pipeline, X, y, model_name=\"LightGBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "Setelah melatih kedua model, kita meninjau fitur mana yang paling berkontribusi terhadap prediksi biaya asuransi. Visualisasi di atas menunjukkan perbedaan strategi yang mencolok antara XGBoost dan LightGBM.\n",
    "\n",
    "### 1. XGBoost: The \"Interaction Hunter\"\n",
    "XGBoost (Model Pemenang kita) sangat menyukai fitur-fitur hasil rekayasa (*Feature Engineering*) yang kita buat.\n",
    "\n",
    "* **Dominasi Mutlak `smoker_obese_interaction`**:\n",
    "    Fitur ini menjadi juara tak terbantahkan dengan skor *importance* melebihi **0.5**. Ini membuktikan bahwa hipotesis kita benar: Risiko (dan biaya) tertinggi bukan hanya karena merokok atau obesitas secara terpisah, melainkan **kombinasi keduanya**. XGBoost langsung mengenali bahwa jika seseorang perokok *dan* obesitas, biayanya akan meledak.\n",
    "* **`bmi_smoker_continuous`**:\n",
    "    Fitur terpenting kedua. Ini menegaskan bahwa bagi perokok, setiap kenaikan angka BMI berdampak sangat besar pada biaya.\n",
    "* **Kesimpulan XGBoost**: Model ini bekerja sangat efektif karena kita membantunya dengan fitur interaksi. Ia \"malas\" melihat fitur dasar (`bmi` atau `children` sendirian) karena fitur turunan kita sudah memberikan sinyal yang jauh lebih kuat.\n",
    "\n",
    "### 2. LightGBM: The \"Raw Data\" Analyst\n",
    "LightGBM memiliki pendekatan yang sangat berbeda. Ia kurang tertarik pada fitur interaksi biner kita dan lebih memilih variabel kontinu asli.\n",
    "\n",
    "* **Fokus pada `bmi` dan `age`**:\n",
    "    LightGBM menempatkan `bmi` (murni) dan `age_bmi_interaction` sebagai fitur teratas. Ia mencoba memecah pohon keputusan berdasarkan angka BMI secara mendetail, bukan berdasarkan kategori \"Obesitas\" yang kita buat.\n",
    "* **Mengabaikan Flag Perokok**:\n",
    "    Yang mengejutkan, fitur terkait status perokok (`smoker_yes`, `smoker_obese_interaction`) justru dianggap tidak terlalu penting dibandingkan variabel demografis kontinu.\n",
    "* **Kelemahan**: Strategi ini mungkin menjadi alasan mengapa LightGBM kalah akurat dari XGBoost. Dalam asuransi kesehatan, status perokok adalah faktor pembeda tarif yang tegas (diskrit), bukan gradasi halus. Dengan terlalu fokus pada BMI kontinu, LightGBM mungkin kehilangan ketegasan pola \"High Risk Group\" yang ditangkap sempurna oleh XGBoost.\n",
    "\n",
    "### Insight & Conclusion\n",
    "\n",
    "1.  **Validasi Feature Engineering**: Kemenangan XGBoost adalah bukti bahwa proses *feature engineering* kita (terutama pembuatan `smoker_obese_interaction`) **sangat sukses**. Tanpa fitur ini, model mungkin akan kesulitan menangkap lonjakan biaya pada kelompok risiko tinggi.\n",
    "2.  **Faktor Risiko Utama**: Bagi perusahaan asuransi, data ini berteriak satu hal: **Saring ketat nasabah yang Merokok dan Obesitas.** Mereka adalah penyumbang varians klaim terbesar.\n",
    "3.  **Rekomendasi**: Pertahankan fitur interaksi tersebut saat *deployment* model, karena itulah \"otak\" utama dari prediksi akurat XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:40:32.953459Z",
     "iopub.status.busy": "2025-11-19T13:40:32.953122Z",
     "iopub.status.idle": "2025-11-19T13:41:41.25734Z",
     "shell.execute_reply": "2025-11-19T13:41:41.256082Z",
     "shell.execute_reply.started": "2025-11-19T13:40:32.953436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Run DNN Workflow\n",
    "dnn_results = run_dnn_cv(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    num_cols=NUM_FEATS,\n",
    "    cat_cols=CAT_FEATS,\n",
    "    n_splits=5,\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network (DNN) Evaluation\n",
    "\n",
    "Kami mencoba pendekatan *Deep Learning* menggunakan arsitektur Neural Network sederhana. Berikut adalah hasil evaluasinya:\n",
    "\n",
    "### 1. Ringkasan Performa\n",
    "* **R2 Score**: **0.8446** (Lebih rendah dari XGBoost 0.8584)\n",
    "* **MAE**: **`$2,659.17`** (Error lebih tinggi ~`$200` dibanding XGBoost)\n",
    "* **RMSE**: **`$4,702.46`**\n",
    "\n",
    "### 2. Mengapa DNN Tidak Optimal di Sini?\n",
    "\n",
    "Meskipun skor R2 sebesar 0.84 menunjukkan model ini \"layak\", namun performanya **kalah konsisten** dibandingkan XGBoost. Ada beberapa alasan teknis mengapa DNN kesulitan mengalahkan *Gradient Boosting* pada kasus ini:\n",
    "\n",
    "#### a. Kutukan Data Tabular (*Tabular Data Struggle*)\n",
    "Deep Learning sangat superior untuk data tidak terstruktur (gambar, teks, suara). Namun, untuk **data tabular** (kolom & baris) dengan jumlah baris yang terbatas (dataset kita < 2000 baris), algoritma berbasis pohon (*Tree-based*) seperti XGBoost hampir selalu menang.\n",
    "* **XGBoost** bekerja dengan membuat \"pemisah\" tegas (misal: Jika `smoker=yes` DAN `bmi > 30`, maka biaya tinggi). Ini sangat cocok dengan pola asuransi.\n",
    "* **DNN** mencoba mencari fungsi matematika yang mulus (*smooth function*) melalui perkalian matriks (bobot & bias). DNN kesulitan menangkap \"lompatan\" risiko yang tajam dan diskrit pada aturan bisnis asuransi.\n",
    "\n",
    "#### b. Instabilitas Antar Fold\n",
    "Perhatikan perbedaan drastis antara **Fold 1 (R2 0.89)** dan **Fold 2 (R2 0.80)**.\n",
    "Jarak performa yang jauh ini menunjukkan bahwa DNN agak **tidak stabil** dan sensitif terhadap pembagian data. Ia mungkin mengalami *overfitting* pada fold tertentu dan gagal menggeneralisasi pola pada fold lainnya.\n",
    "\n",
    "### 3. Kesimpulan\n",
    "Penggunaan Deep Learning pada kasus ini tergolong **\"Overkill\" namun \"Underperforming\"**. Kompleksitas model bertambah, waktu training lebih lama, namun akurasinya justru turun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:41:41.259135Z",
     "iopub.status.busy": "2025-11-19T13:41:41.258777Z",
     "iopub.status.idle": "2025-11-19T13:42:06.507011Z",
     "shell.execute_reply": "2025-11-19T13:42:06.505821Z",
     "shell.execute_reply.started": "2025-11-19T13:41:41.259102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# === Visualisasi Feature Importance DNN ===\n",
    "final_dnn_model, X_dnn_proc, dnn_feats = train_final_dnn(X, y, NUM_FEATS, CAT_FEATS)\n",
    "df_imp_dnn = explain_dnn_feature_importance(final_dnn_model, X_dnn_proc, y, dnn_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN Feature Importance\n",
    "\n",
    "Visualisasi *Permutation Importance* pada DNN menunjukkan pola unik yang berbeda dari model *Tree-based* sebelumnya:\n",
    "\n",
    "1.  **Dominasi `bmi_smoker_continuous`**:\n",
    "    Berbeda dengan XGBoost yang menyukai fitur \"aturan kaku\" (`smoker_obese_interaction` berupa 0/1), DNN justru sangat bergantung pada **`bmi_smoker_continuous`**. Ini masuk akal karena Neural Network bekerja berbasis fungsi matematika dan gradien; ia lebih mudah belajar dari **angka kontinu** yang memiliki gradasi nilai daripada kategori biner yang patah-patah.\n",
    "\n",
    "2.  **Menangkap Pola Non-Linier (`age_sq`)**:\n",
    "    Fitur **`age_sq`** (usia kuadrat) muncul sebagai fitur terpenting kedua. Ini menunjukkan bahwa DNN sedang berusaha memodelkan kurva biaya yang melengkung seiring bertambahnya usia (fungsi eksponensial), sesuatu yang tidak terlalu diprioritaskan oleh model *Tree* yang hanya melakukan pemisahan data (*splitting*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü•ä 5. Final Evaluation and Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T13:42:06.508503Z",
     "iopub.status.busy": "2025-11-19T13:42:06.508136Z",
     "iopub.status.idle": "2025-11-19T13:42:12.240499Z",
     "shell.execute_reply": "2025-11-19T13:42:12.23936Z",
     "shell.execute_reply.started": "2025-11-19T13:42:06.508464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# --- 1. Setup Ulang Pipeline ML ---\n",
    "# Ambil regressor terbaik yang sudah dituning\n",
    "xgb_final = xgb_pipeline.named_steps['regressor']\n",
    "lgbm_final = lgbm_pipeline.named_steps['regressor']\n",
    "\n",
    "xgb_final.set_params(n_jobs=1)\n",
    "lgbm_final.set_params(n_jobs=1)\n",
    "\n",
    "# Buat Ensemble Voting\n",
    "voting_reg = VotingRegressor(estimators=[('xgb', xgb_final), ('lgbm', lgbm_final)], n_jobs=1)\n",
    "\n",
    "# Dictionary Model ML\n",
    "ml_models = {\n",
    "    'XGBoost': xgb_pipeline,\n",
    "    'LightGBM': lgbm_pipeline,\n",
    "    'Ensemble': Pipeline([('preprocessor', my_preprocessor), ('voting', voting_reg)])\n",
    "}\n",
    "\n",
    "# --- Hitung Skor ML & Gabungkan dengan DNN ---\n",
    "print(\"ü•ä FINAL BATTLE: Machine Learning vs Deep Learning\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "leaderboard = []\n",
    "\n",
    "# Loop ML Models\n",
    "scoring = {'r2': 'r2', 'mae': 'neg_mean_absolute_error', 'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "for name, pipe in ml_models.items():\n",
    "    print(f\"Running CV for {name}...\")\n",
    "    cv = cross_validate(pipe, X, y, cv=5, scoring=scoring, n_jobs=1)\n",
    "    leaderboard.append({\n",
    "        'Model': name,\n",
    "        'R2 Score': cv['test_r2'].mean(),\n",
    "        'MAE': -cv['test_mae'].mean(),\n",
    "        'RMSE': -cv['test_rmse'].mean()\n",
    "    })\n",
    "\n",
    "# Masukkan Hasil DNN (Dari variabel dnn_results sebelumnya)\n",
    "leaderboard.append({\n",
    "    'Model': 'Deep Learning (DNN)',\n",
    "    'R2 Score': dnn_results['R2 Score'],\n",
    "    'MAE': dnn_results['MAE'],\n",
    "    'RMSE': dnn_results['RMSE']\n",
    "})\n",
    "\n",
    "# --- Tampilkan Leaderboard Akhir ---\n",
    "comparison_df = pd.DataFrame(leaderboard).set_index('Model').sort_values(by='MAE')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ FINAL LEADERBOARD (Sorted by MAE)\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "winner = comparison_df.index[0]\n",
    "print(f\"üéâ AND THE WINNER IS: {winner} ehehehe!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL BATTLE ANALYSIS: Complexity vs. Efficiency\n",
    "\n",
    "Kita telah mencapai tahap akhir. Setelah mengadu model tunggal (*Single Models*) melawan model gabungan (*Ensemble*) dan Deep Learning, berikut adalah kesimpulannya:\n",
    "\n",
    "### 1. The Champion: XGBoost (Solo) üèÜ\n",
    "* **MAE: `$2,430.26`**\n",
    "* **Analisis:** Secara mengejutkan (atau mungkin tidak), **XGBoost murni** keluar sebagai pemenang. Model ini bekerja sendirian tanpa perlu digabung dengan model lain.\n",
    "* **Kenapa menang?** XGBoost sudah sangat optimal dalam menangkap pola diskrit (patah-patah) pada data asuransi berkat *Feature Engineering* interaksi kita. Ia tidak membutuhkan \"bantuan\" dari model lain untuk memperbaiki prediksinya.\n",
    "\n",
    "### 2. The Ensemble Dilemma (Voting Regressor)\n",
    "* **MAE: `$2,459.31`** (Juara 2)\n",
    "* **Strategi:** Kita menggunakan `VotingRegressor` yang mengambil rata-rata prediksi dari XGBoost dan LightGBM.\n",
    "* **Interpretasi Hasil:**\n",
    "    Hasil Ensemble berada tepat **di tengah-tengah** antara XGBoost (terbaik) dan LightGBM (terburuk).\n",
    "    * Ibaratnya: Jika Anda mencampur Jus Mangga murni yang sangat manis (XGBoost) dengan air tawar (LightGBM), hasilnya memang masih manis, tapi tidak semanis jus murninya.\n",
    "    * **Pelajaran:** Ensembling bekerja paling baik jika model-model penyusunnya memiliki performa yang **setara** atau jika mereka melakukan kesalahan pada jenis data yang **berbeda** (saling melengkapi). Di sini, LightGBM hanya menarik turun rata-rata performa XGBoost.\n",
    "\n",
    "### 3. Deep Learning (DNN)\n",
    "* **MAE: `$2,659.17`** (Posisi Terakhir)\n",
    "* **Analisis:** DNN konsisten berada di posisi terakhir dengan selisih error sekitar **`$230`** lebih mahal dibanding XGBoost. Ini mengonfirmasi bahwa untuk dataset tabular berukuran kecil (<2000 baris) dengan pola aturan bisnis yang tegas, *Neural Networks* bukanlah solusi yang efisien.\n",
    "\n",
    "### Final Verdict\n",
    "Kompleksitas tidak selalu menjamin akurasi. Kita tidak perlu menggunakan *Deep Learning* yang berat atau *Ensemble* yang rumit. Model **XGBoost** tunggal dengan *Feature Engineering* yang cerdas sudah cukup untuk menjadi solusi terbaik (*State-of-the-Art*) untuk permasalahan prediksi biaya asuransi ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÅ 6. Executive Summary & Conclusion\n",
    "\n",
    "Berdasarkan rangkaian eksperimen mulai dari *preprocessing*, *feature engineering*, hingga *model comparison* (Machine Learning vs Deep Learning), berikut adalah kesimpulan strategis dari proyek ini:\n",
    "\n",
    "### 1. Faktor Determinan Klaim Asuransi (Key Risk Drivers)\n",
    "Analisis *Feature Importance* model pemenang (XGBoost) mengungkap fakta bahwa struktur biaya asuransi tidak dipengaruhi oleh faktor tunggal, melainkan **interaksi antar faktor risiko**:\n",
    "\n",
    "* **The \"Double Whammy\" Effect (Perokok + Obesitas)**\n",
    "    Ini adalah faktor paling mematikan dan paling mahal. Fitur `smoker_obese_interaction` mendominasi prediksi. Nasabah yang merokok **DAN** memiliki BMI tinggi (Obesitas) memiliki profil risiko yang jauh lebih tinggi secara eksponensial dibandingkan penjumlahan risiko merokok saja ditambah risiko obesitas saja.\n",
    "* **Gaya Hidup > Demografi Murni**\n",
    "    Faktor gaya hidup (BMI, Status Merokok) memiliki bobot prediksi yang lebih besar dibandingkan faktor demografi statis seperti `region` (wilayah tinggal) atau `sex` (jenis kelamin).\n",
    "* **Penuaan (Aging)**\n",
    "    Usia (`age` dan `age_sq`) tetap menjadi faktor fundamental. Biaya naik seiring bertambahnya umur, dan kenaikannya cenderung melengkung (non-linier), terutama di usia tua.\n",
    "\n",
    "### 2. Penilaian Kelayakan Model (Model Eligibility)\n",
    "\n",
    "Apakah model ini **LAYAK (Eligible)** untuk digunakan dalam sistem penetapan premi asuransi nyata?\n",
    "\n",
    "**Status: ‚úÖ ELIGIBLE WITH GUARDRAILS (Layak dengan Pengawasan)**\n",
    "\n",
    "* **Alasan Layak:**\n",
    "    * **Akurasi Tinggi (R2 ~86%):** Model mampu menjelaskan 86% variasi biaya. Dalam dunia aktuaria di mana perilaku manusia dan penyakit sangat acak, angka ini sangat solid untuk penetapan tarif dasar (*base rate*).\n",
    "    * **Diskriminasi Risiko yang Tajam:** Model sangat jago membedakan mana nasabah \"Murah\" dan nasabah \"Mahal\" berkat *feature engineering* yang kuat.\n",
    "\n",
    "* **Catatan & Risiko (Guardrails):**\n",
    "    * **Margin Error (`$2,430`):** Rata-rata prediksi meleset sekitar `$2,430`. Perusahaan asuransi harus menambahkan **Risk Loading** (biaya cadangan) sebesar nilai ini ke dalam premi agar tidak rugi.\n",
    "    * **Isu Outlier (RMSE Tinggi):** Karena RMSE (`$4,468`) hampir 2x lipat MAE, model terkadang masih *under-predict* pada kasus penyakit katastropik (klaim super besar).\n",
    "    * **Saran Implementasi:** Gunakan prediksi model ini sebagai **acuan dasar (benchmark)**, namun untuk kasus dengan prediksi biaya sangat tinggi, tetap perlukan tinjauan manual (*human underwriter review*)."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 13720,
     "sourceId": 18513,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8814882,
     "sourceId": 13840188,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
